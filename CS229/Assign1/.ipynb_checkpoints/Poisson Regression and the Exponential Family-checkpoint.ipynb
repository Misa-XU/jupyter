{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "## 2. Poisson regression and the exponential family\n",
    "---\n",
    "#### 2.1 Show that the Poisson distribution is in the exponential family.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(y_i;\\mu_i) = exp\\{log(\\frac{e^{-\\mu_i}\\mu_i^y}{y!})\\}\\\\\n",
    "= exp\\{-\\mu_i + y_i log(\\mu_i) - log(y_i!)\\}\n",
    "$$\n",
    "\n",
    "With canonical link function, we have $\\theta_i = \\eta_i$, which means that $g(\\mu_i) = \\theta_i = \\eta_i$. Given the definition of generalize linear model\n",
    "\n",
    "\\# Note that the $\\theta$ is in the context of GLM, means the 'canonical parameter' not the parameters times with x that we'd like to predict\n",
    "$$f_i(y_i) = exp\\{\\frac{y_i\\theta_i - b(\\theta_i))}{a_i(\\phi)} + c(y_i, \\phi)\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find that \n",
    "$$\n",
    "c(y_i, \\phi) = -log(y_i!)\\\\\n",
    "\\eta_i = log(\\mu_i),\\, \\\\\n",
    "\\mu_i = b'(\\eta_i) = (e^{\\eta_i})' = e^{\\eta_i}\n",
    "$$\n",
    "Which satisfy the format of exponential family, and $h_\\theta(x_i) = \\mu_i = e^{\\theta^T x_i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2.2 Find the canonical response function\n",
    "We've already known that $g(\\mu_i) = \\eta_i = log(\\mu_i)$, then the response function $$ \\mu_i = g^{-1}(\\eta_i) = e^{\\eta_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2.3 Derive the stocastic gradient ascent rule using a GLM model with Poisson response y and the canonical response function\n",
    "Suppose each record in the training set is $i.i.d$, then the log-likelihood would be\n",
    "$$\\ell(\\theta) = \\sum_i^m -\\mu_i + y_i log(\\mu_i) - log(y_i!)$$\n",
    "Substitute $\\mu$ with $e^{\\eta_i}$, we could have\n",
    "$$\\ell(\\theta) = \\sum_i^m - e^{\\eta_i} + y_i \\eta_i - log(y_i!)$$\n",
    "As a linear predicter, $\\eta$ would be written as $\\theta^Tx$, then we have\n",
    "$$\\ell(\\theta) = \\sum_i^m - e^{\\theta^Tx_i} + y_i \\theta^Tx_i - log(y_i!)$$\n",
    "\n",
    "Then the partial derivative is\n",
    "$$\\frac {\\partial}{\\partial \\theta} \\ell(\\theta) = \\sum_i^m - x_i e^{\\theta^Tx_i} + y_i x_i \\\\\n",
    "= \\sum_i^m ( - e^{\\theta^Tx_i} + y)x_i$$\n",
    "\n",
    "Since we want to __maximize__ likelihood, the update rule should be \n",
    "$$\\theta_i := \\theta_i + \\alpha (- e^{\\theta^Tx_i} + y)x_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2.4 Show that stocastic gradient ascent on the log-likelihood $log\\,p(\\vec{y}\\,| X;\\theta)$ result in the update rule $\\theta_i := \\theta_i - \\alpha (h(x) - y)x_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a distribution in exponential family, it could always be re-written in the form\n",
    "$$f_i(y_i) = exp\\{\\frac{y_i\\eta_i - b(\\eta_i))}{a_i(\\phi)} + c(y_i, \\phi)\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the fact that $\\eta_i = \\theta^Tx_i $, Then the log-likelihood will be\n",
    "$$\\ell(\\theta) = \\frac{y_i\\theta^Tx_i - b(\\theta^Tx_i))}{a_i(\\phi)} + c(y_i, \\phi)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just assume $a_i(\\phi) = 1$ and discard this term; Meanwhile, according to the property of GLM that $b'(\\eta_i) = \\mu_i = h_\\theta(x)$\n",
    "$$\\frac {\\partial}{\\partial \\theta} \\ell(\\theta) = y_ix_i - \\frac{\\partial}{\\partial \\theta}b(\\theta^Tx_i)\\\\\n",
    "= y_ix_i - \\mu_i \\frac{\\partial}{\\partial \\theta} \\theta^Tx = y_ix_i - \\mu_i x_i = (y - h_\\theta(x))x_i\n",
    "$$\n",
    "Finally, for maximize log-likelihood we find the update rule:\n",
    "$$\\theta_i := \\theta_i + \\alpha (- e^{\\theta^Tx_i} + y)x_i$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
